{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import random\n",
    "import math\n",
    "from sklearn import cross_validation\n",
    "\n",
    "\n",
    "#the class with functions to be used as entry points when\n",
    "#either training (fit) or predicting (predict) with the\n",
    "#decision tree algorithm\n",
    "class DTree:\n",
    "    def fit(self,predictor_columns_data,target_column_data):\n",
    "        self.__root_node = DNode(predictor_columns_data,target_column_data)\n",
    "        self.__root_node.train()\n",
    "        \n",
    "    def predict(self,df_of_new_examples):\n",
    "        #apply the predict function to the whole series, one at a time, this returns the series with the return vals\n",
    "        predictions = df_of_new_examples.apply(self.__root_node.predict,axis=1)\n",
    "        return predictions\n",
    "        \n",
    "    def print_tree(self):\n",
    "        self.__root_node.print_node()\n",
    "        \n",
    "\n",
    "#A class for representing non-leaf nodes in the decision tree\n",
    "class DNode:\n",
    "    \n",
    "    #when we create this node, we pass it training examples to be used at this point\n",
    "    #the predictor columns of these training examples is in predictor_columns_data\n",
    "    #the corresponding target values to those predictor columns are in target_column_data\n",
    "    def __init__(self,predictor_columns_data,target_column_data):\n",
    "\n",
    "        self.__attribute = ''  #the attribute used to sort examples at this node\n",
    "        self.__predictor_columns = predictor_columns_data #the training examples that have been sorted to this node\n",
    "        self.__target_column = target_column_data #the corresponding target values for the training examples\n",
    "        self.__child_nodes = {} #dictionary of the child nodes of this node, indexed by the value they have for self.__attribute\n",
    "        self.__most_common_value_here = '' #for keeping track of which target value is most common among the examples at this node. This is used to make a decision when there's no appropriate child node to follow\n",
    "        \n",
    "    #this should use the training data to determine the best attribute to use\n",
    "    #as is, it just chooses one at random, but you will fix it to use information gain\n",
    "    def choose_attribute(self):\n",
    "        self.__attribute = random.choice(self.__predictor_columns.columns.values) #what a terrible way to choose the attribute!\n",
    "        \n",
    "    #calling this will continue building the tree from this node given its training examples\n",
    "    def train(self):\n",
    "        self.choose_attribute() #'best' attribute at this node\n",
    "        \n",
    "        #in case we need to make a decision here because we don't have any children with a particular attribute value    \n",
    "        self.__most_common_value_here = self.__target_column.value_counts().idxmax()\n",
    "        \n",
    "        #gets all the values that these examples have in our chosen column\n",
    "        attribute_values_here = self.__predictor_columns[self.__attribute].unique()\n",
    "\n",
    "        #going through all possible values this attribute can have\n",
    "        #and creating the appropriate child node\n",
    "        for value in attribute_values_here: \n",
    "             \n",
    "            #the subset of examples with the given value\n",
    "            examples_for_child_predictor_cols = self.__predictor_columns[self.__predictor_columns[self.__attribute] == value] \n",
    "            examples_for_child_target_col = self.__target_column[self.__predictor_columns[self.__attribute] == value] #target values corresponding to the subset of examples with the given value\n",
    "            \n",
    "            #we grabbed the values from the examples themselves, so there should\n",
    "            #be at least one example that has each value, but just in case there isn't\n",
    "            #I don't want to crash the program\n",
    "            if examples_for_child_target_col.empty:\n",
    "                print(\"error: we shouldn't get here\")\n",
    "                \n",
    "            #there are no columns left to use for decisions at the child\n",
    "            #so lets make a leage node based on the most common target value in those examples\n",
    "            elif len(examples_for_child_predictor_cols.columns.values) == 1:  \n",
    "                #create a child with the most common target value here\n",
    "                leaf_child = DLeaf( self.__most_common_value_here )\n",
    "                self.__child_nodes[value] = leaf_child\n",
    "                \n",
    "            #if all child examples have the same target value, we make a leaf node\n",
    "            elif len(examples_for_child_target_col.unique()) == 1: #all child examples have same class\n",
    "                leaf_child = DLeaf( examples_for_child_target_col.unique()[0] ) #make leaf with that class\n",
    "                self.__child_nodes[value] = leaf_child #put the leaf in the dictionary of children nodes\n",
    "                \n",
    "            else: #we have a regular decision node for this attribute value\n",
    "                #get rid of the column for this attribute so it can't be selected again\n",
    "                examples_for_child_predictor_cols = examples_for_child_predictor_cols.drop(self.__attribute,1) \n",
    "                \n",
    "                new_child = DNode(examples_for_child_predictor_cols,examples_for_child_target_col)\n",
    "                new_child.train() #generate the rest of the subtree for this child\n",
    "                self.__child_nodes[value] = new_child #put the new child node in the dictionary of children nodes\n",
    "            \n",
    "\n",
    "    #print out the tree - not the prettiest, but you can see it.\n",
    "    def print_node(self,num_indents = 0):\n",
    "        for i in range(num_indents): \n",
    "            print(\" \",end=''), #print with no newline\n",
    "        print(self.__attribute)\n",
    "        for attr in self.__child_nodes.keys():\n",
    "            for i in range(num_indents): \n",
    "                print(\"|\", end='')\n",
    "            print(\":\"+attr)\n",
    "            self.__child_nodes[attr].print_node(num_indents+1)\n",
    "            \n",
    "    #make a prediction for a single new example\n",
    "    #this only makes sense to call after the tree has been build (with train())\n",
    "    def predict(self,new_example):\n",
    "        #look up the right branch in our dictionary of children\n",
    "        if new_example[self.__attribute] in self.__child_nodes:\n",
    "            node_on_corresponding_branch = self.__child_nodes[new_example[self.__attribute]]\n",
    "            return node_on_corresponding_branch.predict(new_example) #recursively call predict on the child node\n",
    "        else:\n",
    "            return self.__most_common_value_here #there was no child, so we predict the most common class of the examples at this node\n",
    "        \n",
    "#class for representing a leaf node in the tree\n",
    "class DLeaf:\n",
    "    \n",
    "    #when we create the node, all we need to know is what we're going to predict if we get here\n",
    "    def __init__(self,val_in_target_col):\n",
    "        self.__target_value = val_in_target_col\n",
    "    \n",
    "    #just returns the prediction for a new example, \n",
    "    #this was probably called from predict() of a regular node one level up in the tree\n",
    "    def predict(self,new_example):\n",
    "        return self.__target_value\n",
    "    \n",
    "    #for displaying the tree\n",
    "    def print_node(self,num_indents = 0):\n",
    "        for i in range(num_indents): \n",
    "            print(\" \",end='')\n",
    "        print(\"LEAF:\",self.__target_value)\n",
    "        \n",
    "    \n",
    "#simply compares two Pandas series and returns the proportion that match\n",
    "#this can be used to compute the accuracy of the prediction list against\n",
    "#the actual target column\n",
    "def accuracy(series1, series2):\n",
    "    correct = 0.0\n",
    "    for index, value in series1.iteritems():\n",
    "        if value == series2.loc[index]:\n",
    "            correct += 1\n",
    "    return (correct/len(series1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
